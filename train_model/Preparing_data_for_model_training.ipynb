{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zinf2N82Thm32DcTDlWMqSirAyrYEqq3",
      "authorship_tag": "ABX9TyNb2uX9xh0QmdMOgT4NG4+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SknyL/Face_emotion_recognition/blob/main/Preparing_data_for_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка датасета"
      ],
      "metadata": {
        "id": "R-2zKQLBTzVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F31svehPAKS0"
      },
      "outputs": [],
      "source": [
        "!gdown 1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/MyDrive/Colab Notebooks/Emotion Recognition/train.zip' -d '/content/data/'"
      ],
      "metadata": {
        "id": "8OO_KKyn-Cnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для детектирования лиц на изображении используем готовую библиотеку mediapipe"
      ],
      "metadata": {
        "id": "krXeaMLsTjjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX-mMp8Z_5qC",
        "outputId": "d50357b9-dfe8-458c-e868-55da740fee84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.19.6)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import shutil"
      ],
      "metadata": {
        "id": "pNdpeDg7_97o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_img(img):\n",
        "    \"\"\"\n",
        "      Изображение на входе должно быть RGB\n",
        "    \"\"\"\n",
        "    # Создание менеджера контекста для детектора лиц\n",
        "    with mp.solutions.face_detection.FaceDetection(\n",
        "            model_selection=0, min_detection_confidence=0.7) as face_detection:\n",
        "        # Поиск лица на кадре\n",
        "        faces = face_detection.process(img)\n",
        "        # Если лицо не обнаружено возвращается None\n",
        "        if not faces.detections:\n",
        "            return None\n",
        "        for id, detection in enumerate(faces.detections):\n",
        "            # Координаты и размеры бокса с лицом на кадре\n",
        "            bbox = detection.location_data.relative_bounding_box\n",
        "            mul_h = img.shape[0]\n",
        "            mul_w = img.shape[1]\n",
        "            x = int(abs(bbox.xmin) * mul_w)\n",
        "            y = int(abs(bbox.ymin) * mul_h)\n",
        "            w = int(abs(bbox.width) * mul_w)\n",
        "            h = int(abs(bbox.height) * mul_h)\n",
        "            # Обрезка лица из кадра\n",
        "            img_crop = img[y:y+h, x:x+w, :]\n",
        "            return img_crop"
      ],
      "metadata": {
        "id": "GVd-wmQeNi8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Путь для подготовленных изображений\n",
        "croped_path = '/content/data/croped_train/' \n",
        "# Проверка на существование папки\n",
        "if os.path.exists(croped_path): \n",
        "    shutil.rmtree(croped_path)\n",
        "\n",
        "for (root,dirs,files) in os.walk('/content/data/train', topdown=False):\n",
        "    folder = root.split('/')[-1] # Выделение название папки из пути\n",
        "    croped_path = f'/content/data/croped_train/{folder}'\n",
        "    os.makedirs(croped_path) # Создание папки\n",
        "    for file in [root + '/' + file for file in files]:\n",
        "        img = cv2.imread(file, cv2.COLOR_BGR2RGB) # Чтение изображения из папки\n",
        "        img_crop = crop_img(img) # Применение функции обрезки лица из изображения\n",
        "        # Если лицо не было детектированно на изображении цикл начинается заново\n",
        "        if img_crop is None:\n",
        "            continue\n",
        "        # Путь до полученного изображения\n",
        "        file_path = os.path.join(croped_path , file.split('/')[-1])\n",
        "        save_flag = cv2.imwrite(file_path, img_crop) # Запись изображения\n",
        "        print(f'File:{file_path} saved: {save_flag}') # Вывод пути и флага записи"
      ],
      "metadata": {
        "id": "xQNviSTCBVn7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}